{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d41bfd87",
   "metadata": {},
   "source": [
    "# Selecting Continuous Life-Like Cellular Automata for Halting Unpredictability: Evolving for Abiogenesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f872b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this section needs to be run for setup on colab\n",
    "# uncomment and run the commands below if on colab\n",
    "# then restart the runtime and run tests in the next cell\n",
    "\n",
    "\n",
    "#! git clone https://github.com/riveSunder/yuca.git my_yuca\n",
    "#%cd my_yuca\n",
    "#! pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e023cb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python -m testing.test_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f932df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make  cells wider\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8732dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from yuca.multiverse import CA\n",
    "from yuca.cmaes import CMAES\n",
    "from yuca.zoo.librarian import Librarian\n",
    "from yuca.halting_wrapper import HaltingWrapper, SimpleHaltingWrapper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "my_cmap = plt.get_cmap(\"magma\")\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"animation.embed_limit\"] = 256\n",
    "matplotlib.rcParams[\"font.size\"] = 10\n",
    "#matplotlib.rcParams[\"text.usetex\"] = True\n",
    "\n",
    "import IPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb34fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions for plotting animations\n",
    "\n",
    "def plot_4x4(grids):\n",
    "    # grids is a length 16 list of tensors containing CA grids\n",
    "    \n",
    "    global subplot_0\n",
    "    \n",
    "    my_cmap = plt.get_cmap(\"magma\")\n",
    "    fig, ax = plt.subplots(1,1, figsize=(2.25, 2.25), facecolor=\"white\")\n",
    "    \n",
    "    # combine grids\n",
    "    # random CA rule parameters\n",
    "    grid = torch.cat([grids[0], grids[1], grids[2], grids[3]], dim=-1)\n",
    "    # lenia\n",
    "    grid = torch.cat([grid, torch.cat([grids[4], grids[5], grids[6], grids[7]], dim=-1)], dim=-2)\n",
    "    # evolved 1\n",
    "    grid = torch.cat([grid, torch.cat([grids[8], grids[9], grids[10], grids[11]], dim=-1)], dim=-2)\n",
    "    # evolved 2\n",
    "    grid = torch.cat([grid, torch.cat([grids[12], grids[13], grids[14], grids[15]], dim=-1)], dim=-2)\n",
    "    \n",
    "    disp_grid =  1.0 - my_cmap(grid.squeeze())[...,0:3]\n",
    "    \n",
    "    subplot_0 = ax.imshow(disp_grid)\n",
    "    \n",
    "    ax.set_title(\"CA grids\")\n",
    "    tick_step = (grid.shape[-2]//4 )\n",
    "    ax.set_yticks([tick_step//2 + tick_step*kk for kk in range(4)])\n",
    "    ax.set_yticklabels(['typical random rules (a)', 'Lenia rules (b)', \\\n",
    "                        'evo. rules (simple) (c)', 'evo. rules (halting) (d)'])\n",
    "    ax.set_xticklabels('')\n",
    "    return fig, ax\n",
    "    \n",
    "def update(hh):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        global grids\n",
    "        global population\n",
    "        global subplot_0\n",
    "\n",
    "        my_cmap = plt.get_cmap(\"magma\")\n",
    "\n",
    "        for ii in range(len(grids)):\n",
    "            grids[ii] = population[ii](grids[ii])\n",
    "\n",
    "        # combine grids\n",
    "        # random CA rule parameters\n",
    "        grid = torch.cat([grids[0], grids[1], grids[2], grids[3]], dim=-1)\n",
    "        # lenia\n",
    "        grid = torch.cat([grid, torch.cat([grids[4], grids[5], grids[6], grids[7]], dim=-1)], dim=-2)\n",
    "        # evolved 1\n",
    "        grid = torch.cat([grid, torch.cat([grids[8], grids[9], grids[10], grids[11]], dim=-1)], dim=-2)\n",
    "        # evolved 2\n",
    "        grid = torch.cat([grid, torch.cat([grids[12], grids[13], grids[14], grids[15]], dim=-1)], dim=-2)\n",
    "\n",
    "        disp_grid =  1.0 - my_cmap(grid.squeeze())[...,0:3]\n",
    "\n",
    "        subplot_0.set_array(disp_grid)\n",
    "        ax.set_yticklabels(['a','b','c','d'])\n",
    "        ax.set_xticklabels('')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ec690d",
   "metadata": {},
   "source": [
    "## Section 1: \n",
    "### Visualize typical CA dynamics: evolved with random fitness, complex Lenia CA, and CA with evolved rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb11c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = CA()\n",
    "cmaes = CMAES(population_size=16)\n",
    "use_random_evo = True\n",
    "\n",
    "lib = Librarian()\n",
    "lib.index\n",
    "lenia_configs = [\"orbium.npy\", \"p_sinus_labens.npy\", \"geminium.npy\", \"synorbium.npy\"]\n",
    "random_configs = [\"exp_local_glaberish_orbium_random_1649112702_seed3_config.npy\",\\\n",
    "                 \"exp_local_glaberish_orbium_random_1649112702_seed5_config.npy\",\\\n",
    "                 \"exp_local_glaberish_orbium_random_1649112702_seed7_config.npy\",\\\n",
    "                 \"ca_configs/exp_local_glaberish_geminium_random_1649461964_seed113.npy\"]\n",
    "evo_configs = [\\\n",
    "               \"s643.npy\", \\\n",
    "               \"exp_local_glaberish_geminium_simple_halt_1649264299_seed11_config.npy\",\\\n",
    "               \"exp_local_glaberish_geminium_simple_halt_1649264299_seed7_config.npy\",\\\n",
    "               \"exp_local_glaberish_geminium_simple_halt_1649312229_seed5_config.npy\",\\\n",
    "               \"exp_local_glaberish_orbium_halt_1649112713_seed3_config.npy\",\\\n",
    "               \"exp_local_glaberish_orbium_halt_1649112713_seed7_config.npy\",\\\n",
    "               \"s613.npy\", \\\n",
    "               \"exp_local_glaberish_geminium_halt_1651935163_seed5.npy\"\n",
    "              ]\n",
    "\n",
    "#\"exp_local_glaberish_orbium_halt_1649112713_seed3_config.npy\", \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f8b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmaes.reset()\n",
    "cmaes.initialize_population()\n",
    "\n",
    "population = []\n",
    "\n",
    "\n",
    "for jj in range(4):\n",
    "    \n",
    "    ca = CA()\n",
    "    ca.no_grad()\n",
    "    ca.set_params(cmaes.population[jj].get_action())\n",
    "    \n",
    "    if use_random_evo:\n",
    "        ca.restore_config(random_configs[jj])\n",
    "        \n",
    "    population.append(ca)\n",
    "\n",
    "for jj in range(4,8):\n",
    "    # load lenia configs\n",
    "    ca = CA()\n",
    "    ca.no_grad()\n",
    "    ca.restore_config(lenia_configs[jj-4])\n",
    "\n",
    "    population.append(ca)\n",
    "\n",
    "for jj in range(8,16):\n",
    "    # load lenia configs\n",
    "    ca = CA()\n",
    "    ca.no_grad()\n",
    "    ca.restore_config(evo_configs[jj-8])\n",
    "    \n",
    "    population.append(ca)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b78be2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#3141592\n",
    "torch.manual_seed(314)\n",
    "rand_grid = torch.rand(1,1,96,96)\n",
    "rand_grid.requires_grad = False\n",
    "grids = [1.0 * rand_grid] * 16\n",
    "\n",
    "num_frames = 100\n",
    "fig, ax = plot_4x4(grids)\n",
    "#plt.close(\"all\")\n",
    "plt.show()\n",
    "\n",
    "save_gif = False\n",
    "if (save_gif):\n",
    "    matplotlib.animation.FuncAnimation(fig, update, frames=num_frames, interval=100).save(\"uniform_init_cas.gif\")\n",
    "    grids = [1.0 * rand_grid] * 16\n",
    "else:\n",
    "    pass\n",
    "\n",
    "IPython.display.HTML(matplotlib.animation.FuncAnimation(fig, update, frames=num_frames, interval=100).to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44acda95",
   "metadata": {},
   "source": [
    "## Section 2\n",
    "### Try predicting CA halting for yourself. How hard is it to predict whether a complex CA with vanish? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f30a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# how easy/hard is it to predict halting? \n",
    "# try it yourself and see\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "my_configs = [\"orbium.npy\", \\\n",
    "              \"s613.npy\",\\\n",
    "             \"exp_local_glaberish_orbium_random_1649112702_seed3_config.npy\",\\\n",
    "             \"exp_local_glaberish_geminium_simple_halt_1649264299_seed11_config.npy\"]\n",
    "\n",
    "shuffle(my_configs)\n",
    "batch_size = 4\n",
    "first_steps = 13\n",
    "ca_steps = 256\n",
    "ready_to_go = True\n",
    "over_count = 0\n",
    "\n",
    "for my_config in my_configs:\n",
    "    \n",
    "    if ready_to_go:\n",
    "        pass\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ready = False\n",
    "        while not ready:\n",
    "            ca = CA()\n",
    "\n",
    "            ca.restore_config(my_config)\n",
    "\n",
    "            # 'training set'\n",
    "            grids = torch.rand(batch_size,1,96,96)\n",
    "\n",
    "            for step in range(first_steps):\n",
    "                grids = ca(grids)\n",
    "\n",
    "            first_grids = grids * 1.0\n",
    "\n",
    "            for step in range(ca_steps):\n",
    "                grids = ca(grids)\n",
    "\n",
    "            fig, ax = plt.subplots(2, batch_size, figsize=( batch_size,2))\n",
    "\n",
    "            for xx in range(batch_size):\n",
    "                ax[0,xx].imshow(first_grids[xx].squeeze())\n",
    "                ax[1,xx].imshow(grids[xx].squeeze())\n",
    "\n",
    "                ax[0,xx].set_xticklabels('')\n",
    "                ax[0,xx].set_yticklabels('')\n",
    "                ax[1,xx].set_xticklabels('')\n",
    "                ax[1,xx].set_yticklabels('')\n",
    "\n",
    "                ax[0,xx].set_title(f\"{xx}\")\n",
    "                    \n",
    "            ax[0,0].set_yticks([grids.shape[-2]//2])\n",
    "            ax[0,0].set_yticklabels([f\"{first_steps} steps\"], fontsize=3, rotation=0)\n",
    "\n",
    "            ax[1,0].set_yticks([grids.shape[-2]//2])\n",
    "            ax[1,0].set_yticklabels([f\"{ca_steps} steps\"], fontsize=3, rotation=0)\n",
    "            plt.suptitle(\"training\", y=1.1)\n",
    "            #plt.tight_layout()\n",
    "\n",
    "            \n",
    "            ready = bool(int(input(\"ready to predict 1/0?\")))\n",
    "        \n",
    "            plt.show()\n",
    "\n",
    "        # 'training set'\n",
    "        grids = torch.rand(batch_size,1,96,96)\n",
    "\n",
    "        for step in range(first_steps):\n",
    "            grids = ca(grids)\n",
    "\n",
    "        first_grids = grids * 1.0\n",
    "        \n",
    "        for step in range(ca_steps):\n",
    "            grids = ca(grids)\n",
    "\n",
    "        fig, ax = plt.subplots(2, batch_size, figsize=(batch_size,2))\n",
    "        \n",
    "        for xx in range(batch_size):\n",
    "            ax[0,xx].imshow(first_grids[xx].squeeze())\n",
    "                      \n",
    "            ax[0,xx].set_xticklabels('')\n",
    "            ax[0,xx].set_yticklabels('')\n",
    "            ax[1,xx].set_xticklabels('')\n",
    "            ax[1,xx].set_yticklabels('')\n",
    "            \n",
    "            ax[0,xx].set_title(f\"{xx}\")\n",
    "  \n",
    "        ax[0,0].set_yticks([grids.shape[-2]//2])\n",
    "        ax[0,0].set_yticklabels([f\"{first_steps} steps\"], fontsize=3, rotation=0)\n",
    "        \n",
    "        ax[1,0].set_yticks([grids.shape[-2]//2])\n",
    "        ax[1,0].set_yticklabels([f\"{ca_steps} steps\"], fontsize=3, rotation=0)\n",
    "            \n",
    "        plt.suptitle(\"inference\", y=1.1)\n",
    "        #plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        guesses = []\n",
    "        \n",
    "        for ll in range(4):\n",
    "            \n",
    "            guesses.append(bool(int(input(f\"Will grid {ll} vanish?\"))))\n",
    "            \n",
    "\n",
    "        for step in range(ca_steps):\n",
    "            grids = ca(grids)\n",
    "\n",
    "        fig, ax = plt.subplots(2, batch_size, figsize=(batch_size,2))\n",
    "\n",
    "        \n",
    "        actual = []\n",
    "        for ll in range(4):\n",
    "            actual.append(grids[ll].mean().item() == 0.0)\n",
    "            \n",
    "        for xx in range(batch_size):\n",
    "            ax[0,xx].imshow(first_grids[xx].squeeze())\n",
    "            ax[1,xx].imshow(grids[xx].squeeze())\n",
    "\n",
    "            ax[0,xx].set_xticklabels('')\n",
    "            ax[0,xx].set_yticklabels('')\n",
    "            ax[1,xx].set_xticklabels('')\n",
    "            ax[1,xx].set_yticklabels('')\n",
    "            \n",
    "            ax[0,xx].set_title(f\"{guesses[xx] == actual[xx]}\") \n",
    "        \n",
    "\n",
    "        ax[0,0].set_yticks([grids.shape[-2]//2])\n",
    "        ax[0,0].set_yticklabels([f\"{first_steps} steps\"], fontsize=3, rotation=0)\n",
    "        \n",
    "        ax[1,0].set_yticks([grids.shape[-2]//2])\n",
    "        ax[1,0].set_yticklabels([f\"{ca_steps} steps\"], fontsize=3, rotation=0)\n",
    "        plt.suptitle(\"inference check\", y=1.1)\n",
    "        #plt.tight_layout()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "        actual = []\n",
    "        for ll in range(4):\n",
    "            actual.append(grids[ll].mean().item() == 0.0)\n",
    "        \n",
    "        correct_count = np.sum(np.array(actual) == np.array(guesses))\n",
    "        \n",
    "        msg = f\"\\n\\n *****accuracy for config {my_config} is {correct_count} of {len(actual)}******\\n\\n\"\n",
    "        \n",
    "        print(msg)\n",
    "        \n",
    "        over_count += 1\n",
    "        \n",
    "        if over_count == len(my_configs):\n",
    "            break\n",
    "        ready_to_go = bool(int(input(\"\\nwant to make some more halting predictions?\\n\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650dfccd",
   "metadata": {},
   "source": [
    "## Section 3\n",
    "### Evolve CA rules for halting unpredictability, or for roughly even proportion of vanishing and persistent cell values\n",
    "\n",
    "* HaltingWrapper: generates a fitness value based on training convolutional neural networs to predict vanishing or persistent patterns\n",
    "* SimpleHaltingWrapper: selects based on an even proportion of vanishing and persistent patterns (no prediction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c883e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolve your own CA \n",
    "my_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "visualize = True\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# SimpleHaltingWrapper selects for an even proportion of vanishing and persistent grids\n",
    "# change SimpleHaltingWrapepr to HaltingWrapper for halting unpredictability evollution\n",
    "kwargs = {\"env_fn\": SimpleHaltingWrapper,\\\n",
    "          \"batch_size\": 64,\\\n",
    "          \"tag\": \"orbish\",\\\n",
    "          \"population_size\": 16,\\\n",
    "          \"generations\": 10,\\\n",
    "          \"replicates\": 1,\\\n",
    "          \"device\": my_device,\\\n",
    "          \"ca_steps\": 256,\\\n",
    "          \"kernel_radius\": 13,\\\n",
    "          \"dim\": 128\\\n",
    "         }\n",
    "\n",
    "cmaes = CMAES(**kwargs)\n",
    "cmaes.reset()\n",
    "cmaes.initialize_population()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize:\n",
    "    population = []\n",
    "\n",
    "\n",
    "    for jj in range(cmaes.population_size):\n",
    "\n",
    "        ca = CA(tag=kwargs[\"tag\"])\n",
    "        ca.no_grad()\n",
    "        ca.set_params(cmaes.population[jj].get_action())\n",
    "\n",
    "        population.append(ca)\n",
    "        \n",
    "    torch.manual_seed(31415)\n",
    "    rand_grid = torch.rand(1,1,96,96)\n",
    "    rand_grid.requires_grad = False\n",
    "    grids = [1.0 * rand_grid] * 16\n",
    "\n",
    "    # changed to 75 due to problems with higher num_frames in colab\n",
    "    num_frames = 75 #kwargs[\"ca_steps\"]\n",
    "    fig, ax = plot_4x4(grids)\n",
    "    #plt.close(\"all\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    num_frames = 0\n",
    "    \n",
    "    rand_grid = torch.rand(1,1,96,96)\n",
    "    grids = [1.0 * rand_grid] * 16\n",
    "    fig, ax = plot_4x4(grids)\n",
    "\n",
    "IPython.display.HTML(matplotlib.animation.FuncAnimation(fig, update, frames=num_frames, interval=100).to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6806283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run evolution \n",
    "cmaes.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646920e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if visualize:\n",
    "    population = []\n",
    "\n",
    "\n",
    "    for jj in range(cmaes.population_size):\n",
    "\n",
    "        ca = CA(tag=kwargs[\"tag\"])\n",
    "        ca.no_grad()\n",
    "        ca.set_params(cmaes.population[jj].get_action())\n",
    "\n",
    "        population.append(ca)\n",
    "        \n",
    "    torch.manual_seed(31415)\n",
    "    rand_grid = torch.rand(1,1,96,96)\n",
    "    rand_grid.requires_grad = False\n",
    "    grids = [1.0 * rand_grid] * 16\n",
    "\n",
    "    # changed to 75 due to problems with higher num_frames in colab\n",
    "    num_frames = 75 #kwargs[\"ca_steps\"]\n",
    "    fig, ax = plot_4x4(grids)\n",
    "    #plt.close(\"all\")\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    num_frames = 0\n",
    "    \n",
    "    rand_grid = torch.rand(1,1,96,96)\n",
    "    grids = [1.0 * rand_grid] * 16\n",
    "    fig, ax = plot_4x4(grids)\n",
    "\n",
    "save_gif = False\n",
    "if (save_gif):\n",
    "    matplotlib.animation.FuncAnimation(fig, update, frames=num_frames, interval=100).save(\"evolved_geminish_ca.gif\")\n",
    "    grids = [1.0 * rand_grid] * 16\n",
    "else:\n",
    "    pass\n",
    "\n",
    "    \n",
    "IPython.display.HTML(matplotlib.animation.FuncAnimation(fig, update, frames=num_frames, interval=100).to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e01d2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
